{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right\" src=\"images/surfsara.png\">\n",
    "<br/>\n",
    "<hr style=\"clear: both\" />\n",
    "\n",
    "# Machine Learning - random forests in Spark\n",
    "In the previous notebook you have seen how to explore a credit data set, preprocess it, train a decision tree, and evaluate the model's performance.\n",
    "\n",
    "In this notebook, you will work on a similar problem. However, instead of a credit data set, we will work on the well-known [Covertype data set](https://archive.ics.uci.edu/ml/datasets/covertype). This data set contains cartographic variables, such as elevation and slope, and you will need to predict the _type_ of forest cover. There are seven possible forest cover types, so we are dealing with a multiclass classification problem.\n",
    "\n",
    "Whereas we used decision trees in our last notebook, we will use a more powerful model this time, called a random forest. As the name suggests, the random forest will build multiple trees, based on random subsets of our data, and with random subsets of our features at each node in the tree. When we want to predict a new instance, we simply combine the predictions of the invididual trees to arrive at the final classification.\n",
    "\n",
    "We will generally follow the structure of the last notebook, but will depart from it in certain cases.\n",
    "\n",
    "**A general hint: it may help to keep the previous notebook opened for reference.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with all our notebooks, we will start by setting up a SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the Covertype data set. This data set has been preprocessed a bit for your convenience, and can be loaded from Parquet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype_df = spark.read.load(\"../data/covtype.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "Count the number of rows in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "Inspect the first few rows of the data set to verify the data makes sense to you. Please note that the data set has been preprocessed by converting the original one-hot encoded binary columns of the soil and wilderness type to a numeric variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "We would like to get an idea of the number of instances per class. If one class is vastly over-represented, for example by 90%, a classifier may simply decide to always predict this class. This will provide very high accuracy (close to 90%, probably), but will not generalise very well. In that case, we may need to resample our data set to account for this fact, or perform some other tricks.\n",
    "\n",
    "Calculate the number of instances per class, ordered from most-occurring to least-occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that some classes are over-represented, and others under-represented. Although we will ignore this observation for now, we must be aware of the impact this will have on our models and their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some idea of what our data looks like, we will need to assemble the relevant features into feature vectors. As in the previous notebook, we will use the [`VectorAssembler`](https://spark.apache.org/docs/2.1.1/ml-features.html#vectorassembler) for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "Make a list of columns you would like to include in the input feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_column_names = [\n",
    "    <FILL IN>\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "Use the [`VectorAssembler`](https://spark.apache.org/docs/2.1.1/ml-features.html#vectorassembler) to create a new data set with the feature vectors added. Remember: the `VectorAssembler` needs to know the input columns and the output columns.\n",
    "\n",
    "**Hint**: it may help to keep the previous notebook open for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler  \n",
    "\n",
    "assembler = VectorAssembler(<FILL IN>)\n",
    "covtype_features_df = assembler.transform(<FILL IN>)\n",
    "covtype_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "Now that we have feature vectors, we need to deal with the two categorical features contained in the data set, `wilderness` and `soil`. Use the [`VectorIndexer`](https://spark.apache.org/docs/2.1.1/ml-features.html#vectorindexer) to convert these features into categorical features. As with all transformers, the `VectorIndexer` requires input and output column names. In addition, it needs to know the maximum number of categories, called `maxCategories`.\n",
    "\n",
    "**Hint**: be careful in specifying the maximum number of categories. You can calculate the number of distinct values of a column by first selecting it, and then using the [`distinct`](http://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame.distinct) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "indexer = VectorIndexer(<FILL IN>)\n",
    "model = indexer.fit(<FILL IN>)\n",
    "covtype_features_idx_df = model.transform(<FILL IN>)\n",
    "covtype_features_idx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7\n",
    "This assignment doesn't require any programming. The following cell will show the metadata for the column that was added by the `VectorIndexer`. Verify that the correct numeric and categorical are present. How can you tell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype_features_idx_df.schema[-1].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "Having successfully preprocessed our data set, we will need to split our data into a training and test set. The following cell will split it 80%-20%, for training and test, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = covtype_features_idx_df.randomSplit([0.8, 0.2], 0)\n",
    "train_data.count(), test_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 8\n",
    "We are now ready to fit a random forest classifier on our training data. Please fill out the relevant information to train our model.\n",
    "\n",
    "**Hint**: because of the data size, please keep the number of trees relatively low (i.e. fewer than 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=<FILL IN>,\n",
    "    labelCol=<FILL IN>,\n",
    "    numTrees=<FILL IN>,\n",
    "    maxDepth=<FILL IN>,\n",
    "    seed=<FILL IN>\n",
    ")\n",
    "model = rf.fit(train_data)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 9\n",
    "With the trained model, transform the test data to obtain the predictions. Have a look at the first prediction for verification (second line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = <FILL IN>\n",
    "<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "Having obtained the model's predictions, we can evaluate the model's performance. Instead of the `BinaryClassificationEvaluator`, we will use the `MulticlassClassificationEvaluator` and calculate the model's accuracy. A random classifier will have an accuracy of 37%. How does your model compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Cover_Type', metricName='accuracy')\n",
    "evaluator.evaluate(predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 10\n",
    "Try to play around with the different settings of the `RandomForestClassifier`. Can you improve on the result above? What seems to influence performance, and why do you thing that is?\n",
    "\n",
    "**Hint**: an outline to train, predict and evaluate in a single cell is provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=<FILL IN>,\n",
    "    labelCol=<FILL IN>,\n",
    "    numTrees=<FILL IN>,\n",
    "    maxDepth=<FILL IN>,\n",
    "    seed=<FILL IN>\n",
    ")\n",
    "model = rf.fit(train_data)\n",
    "predictions = model.transform(test_data)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Cover_Type', metricName='accuracy')\n",
    "evaluator.evaluate(predictions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 11\n",
    "We can plot the the importance of each feature using seaborn. Do the importances make sense to you? Why? Why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "mpl.rcParams['axes.labelsize'] = 24\n",
    "mpl.rcParams['xtick.labelsize'] = 18\n",
    "mpl.rcParams['ytick.labelsize'] = 18\n",
    "\n",
    "importances_df = pd \\\n",
    "    .DataFrame({'importance': model.featureImportances.toArray(), 'feature': feature_column_names}) \\\n",
    "    .sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(16, 8))    \n",
    "sns.barplot(data=importances_df, x='feature', y='importance')\n",
    "plt.xticks(rotation=90, fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
